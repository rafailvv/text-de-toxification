{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2023-11-05T13:11:09.175469900Z",
     "start_time": "2023-11-05T13:11:09.082839500Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "data": {
      "text/plain": "   id                                          reference  \\\n0   0  If Alkar is flooding her with psychic waste, t...   \n1   1                          Now you're getting nasty.   \n2   2           Well, we could spare your life, for one.   \n3   3          Ah! Monkey, you've got to snap out of it.   \n4   4                   I've got orders to put her down.   \n\n                                         translation  similarity  lenght_diff  \\\n0  if Alkar floods her with her mental waste, it ...    0.785171     0.010309   \n1                        you're becoming disgusting.    0.749687     0.071429   \n2                      well, we can spare your life.    0.919051     0.268293   \n3                       monkey, you have to wake up.    0.664333     0.309524   \n4                         I have orders to kill her.    0.726639     0.181818   \n\n    ref_tox   trn_tox  \n0  0.014195  0.981983  \n1  0.065473  0.999039  \n2  0.213313  0.985068  \n3  0.053362  0.994215  \n4  0.009402  0.999348  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>reference</th>\n      <th>translation</th>\n      <th>similarity</th>\n      <th>lenght_diff</th>\n      <th>ref_tox</th>\n      <th>trn_tox</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>If Alkar is flooding her with psychic waste, t...</td>\n      <td>if Alkar floods her with her mental waste, it ...</td>\n      <td>0.785171</td>\n      <td>0.010309</td>\n      <td>0.014195</td>\n      <td>0.981983</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>Now you're getting nasty.</td>\n      <td>you're becoming disgusting.</td>\n      <td>0.749687</td>\n      <td>0.071429</td>\n      <td>0.065473</td>\n      <td>0.999039</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2</td>\n      <td>Well, we could spare your life, for one.</td>\n      <td>well, we can spare your life.</td>\n      <td>0.919051</td>\n      <td>0.268293</td>\n      <td>0.213313</td>\n      <td>0.985068</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3</td>\n      <td>Ah! Monkey, you've got to snap out of it.</td>\n      <td>monkey, you have to wake up.</td>\n      <td>0.664333</td>\n      <td>0.309524</td>\n      <td>0.053362</td>\n      <td>0.994215</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>4</td>\n      <td>I've got orders to put her down.</td>\n      <td>I have orders to kill her.</td>\n      <td>0.726639</td>\n      <td>0.181818</td>\n      <td>0.009402</td>\n      <td>0.999348</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define the threshold for toxicity\n",
    "TOXICITY_THRESHOLD = 0.8\n",
    "DATA_PATH = '../data/'\n",
    "# Load the dataset\n",
    "df = pd.read_csv(DATA_PATH + 'raw/filtered.tsv', delimiter='\\t')\n",
    "df.head()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-05T13:11:11.233051700Z",
     "start_time": "2023-11-05T13:11:09.125256900Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "# Build a dictionary of toxic phrases and their replacements\n",
    "toxic_dict = {}\n",
    "for index, row in df.iterrows():\n",
    "    if row['ref_tox'] > TOXICITY_THRESHOLD:\n",
    "        toxic_dict[row['reference'].lower()] = row['translation'].lower()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-05T13:17:29.061415800Z",
     "start_time": "2023-11-05T13:16:49.190071700Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "# Helper function to maintain the same case\n",
    "def replace_with_same_case(match_obj):\n",
    "    match_str = match_obj.group(0)\n",
    "    replacement = toxic_dict[match_str.lower()]\n",
    "    if match_str[0].isupper():\n",
    "        return replacement.capitalize()\n",
    "    return replacement\n",
    "\n",
    "# Function to detoxify text\n",
    "def detoxify(text):\n",
    "    pattern = re.compile('|'.join(re.escape(key) for key in toxic_dict.keys()), re.IGNORECASE)\n",
    "    return pattern.sub(replace_with_same_case, text)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-05T13:17:29.077415100Z",
     "start_time": "2023-11-05T13:17:29.064414Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I like this.\n"
     ]
    }
   ],
   "source": [
    "# Test the function with a new sentence\n",
    "test_sentence = \"I like that shit.\"\n",
    "print(detoxify(test_sentence))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-04T16:58:15.408900800Z",
     "start_time": "2023-11-04T16:57:29.388879700Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You want to fool me so i don't know what's going on.\n"
     ]
    }
   ],
   "source": [
    "# Test the function with a new sentence\n",
    "test_sentence = \"Trying to keep me fucking drugged so I don't know what's going on.\"\n",
    "print(detoxify(test_sentence))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-04T16:58:36.826423100Z",
     "start_time": "2023-11-04T16:58:34.407133400Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Oh, man, i wanted an old american football game, man!\n"
     ]
    }
   ],
   "source": [
    "# Test the function with a new sentence\n",
    "test_sentence = \"Damn,man,i wanted the old football coach,man!\"\n",
    "print(detoxify(test_sentence))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-04T16:58:41.753841400Z",
     "start_time": "2023-11-04T16:58:40.199926800Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "classifier = pipeline('sentiment-analysis', model='distilbert-base-uncased-finetuned-sst-2-english')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-05T13:19:08.148501800Z",
     "start_time": "2023-11-05T13:18:37.115752800Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "def is_toxic(text_to_analyze, comments = False):\n",
    "  # Run the classifier (model and tokenizer)\n",
    "  results = classifier(text_to_analyze)\n",
    "\n",
    "  # Interpret the results\n",
    "  for result in results:\n",
    "      label = result['label']\n",
    "      score = result['score']\n",
    "\n",
    "      # Heuristic for toxicity based on negative sentiment score\n",
    "      res = label == 'NEGATIVE' and score > TOXICITY_THRESHOLD\n",
    "      if comments:\n",
    "        print(f\"Label: {label}, Score: {score}\")\n",
    "      return res"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-05T13:19:15.160858Z",
     "start_time": "2023-11-05T13:19:15.147861200Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Accuracy: 0.2\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "data_test = pd.read_csv(DATA_PATH + '/interim/test.csv')\n",
    "test_texts = data_test['reference'].tolist()\n",
    "random.shuffle(test_texts)\n",
    "test_texts = test_texts[:20]\n",
    "\n",
    "not_toxic = 0\n",
    "\n",
    "for toxic_text in test_texts:\n",
    "    text_to_analyze =detoxify(toxic_text)\n",
    "    toxic = is_toxic(text_to_analyze, False)\n",
    "    if not toxic:\n",
    "      not_toxic += 1\n",
    "print(\"\\nAccuracy:\", not_toxic/len(test_texts))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-05T13:20:59.709596300Z",
     "start_time": "2023-11-05T13:20:14.420339700Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "from datasets import load_metric\n",
    "metric = load_metric(\"sacrebleu\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-05T13:22:10.336963800Z",
     "start_time": "2023-11-05T13:22:08.389895800Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "data": {
      "text/plain": "{'score': 19.40789466901169,\n 'counts': [531, 258, 127, 64],\n 'totals': [1097, 997, 897, 800],\n 'precisions': [48.40474020054695, 25.87763289869609, 14.158305462653288, 8.0],\n 'bp': 1.0,\n 'sys_len': 1097,\n 'ref_len': 994}"
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_test = pd.read_csv(DATA_PATH + 'interim/test.csv').head(100)\n",
    "test_texts_reference = data_test['reference'].tolist()\n",
    "test_texts_translation = [[data] for data in data_test['translation'].tolist()]\n",
    "\n",
    "predictions = [detoxify(toxic_text) for toxic_text in test_texts_reference]\n",
    "metric.compute(predictions = predictions, references=test_texts_translation)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-05T13:25:42.304823Z",
     "start_time": "2023-11-05T13:22:10.338963800Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
