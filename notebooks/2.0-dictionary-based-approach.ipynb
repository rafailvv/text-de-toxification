{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2023-11-04T16:53:15.603078600Z",
     "start_time": "2023-11-04T16:53:15.591080300Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "data": {
      "text/plain": "   id                                          reference  \\\n0   0  If Alkar is flooding her with psychic waste, t...   \n1   1                          Now you're getting nasty.   \n2   2           Well, we could spare your life, for one.   \n3   3          Ah! Monkey, you've got to snap out of it.   \n4   4                   I've got orders to put her down.   \n\n                                         translation  similarity  lenght_diff  \\\n0  if Alkar floods her with her mental waste, it ...    0.785171     0.010309   \n1                        you're becoming disgusting.    0.749687     0.071429   \n2                      well, we can spare your life.    0.919051     0.268293   \n3                       monkey, you have to wake up.    0.664333     0.309524   \n4                         I have orders to kill her.    0.726639     0.181818   \n\n    ref_tox   trn_tox  \n0  0.014195  0.981983  \n1  0.065473  0.999039  \n2  0.213313  0.985068  \n3  0.053362  0.994215  \n4  0.009402  0.999348  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>reference</th>\n      <th>translation</th>\n      <th>similarity</th>\n      <th>lenght_diff</th>\n      <th>ref_tox</th>\n      <th>trn_tox</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>If Alkar is flooding her with psychic waste, t...</td>\n      <td>if Alkar floods her with her mental waste, it ...</td>\n      <td>0.785171</td>\n      <td>0.010309</td>\n      <td>0.014195</td>\n      <td>0.981983</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>Now you're getting nasty.</td>\n      <td>you're becoming disgusting.</td>\n      <td>0.749687</td>\n      <td>0.071429</td>\n      <td>0.065473</td>\n      <td>0.999039</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2</td>\n      <td>Well, we could spare your life, for one.</td>\n      <td>well, we can spare your life.</td>\n      <td>0.919051</td>\n      <td>0.268293</td>\n      <td>0.213313</td>\n      <td>0.985068</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3</td>\n      <td>Ah! Monkey, you've got to snap out of it.</td>\n      <td>monkey, you have to wake up.</td>\n      <td>0.664333</td>\n      <td>0.309524</td>\n      <td>0.053362</td>\n      <td>0.994215</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>4</td>\n      <td>I've got orders to put her down.</td>\n      <td>I have orders to kill her.</td>\n      <td>0.726639</td>\n      <td>0.181818</td>\n      <td>0.009402</td>\n      <td>0.999348</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define the threshold for toxicity\n",
    "TOXICITY_THRESHOLD = 0.8\n",
    "DATA_PATH = '../data/'\n",
    "# Load the dataset\n",
    "df = pd.read_csv(DATA_PATH + 'raw/filtered.tsv', delimiter='\\t')\n",
    "df.head()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-04T16:53:18.359004300Z",
     "start_time": "2023-11-04T16:53:15.607106Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "# Build a dictionary of toxic phrases and their replacements\n",
    "toxic_dict = {}\n",
    "for index, row in df.iterrows():\n",
    "    if row['ref_tox'] > TOXICITY_THRESHOLD:\n",
    "        toxic_dict[row['reference'].lower()] = row['translation'].lower()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-04T16:54:43.560195700Z",
     "start_time": "2023-11-04T16:53:57.378041500Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "# Helper function to maintain the same case\n",
    "def replace_with_same_case(match_obj):\n",
    "    match_str = match_obj.group(0)\n",
    "    replacement = toxic_dict[match_str.lower()]\n",
    "    if match_str[0].isupper():\n",
    "        return replacement.capitalize()\n",
    "    return replacement\n",
    "\n",
    "# Function to detoxify text\n",
    "def detoxify(text):\n",
    "    pattern = re.compile('|'.join(re.escape(key) for key in toxic_dict.keys()), re.IGNORECASE)\n",
    "    return pattern.sub(replace_with_same_case, text)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-04T16:57:27.571Z",
     "start_time": "2023-11-04T16:57:27.543997100Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I like this.\n"
     ]
    }
   ],
   "source": [
    "# Test the function with a new sentence\n",
    "test_sentence = \"I like that shit.\"\n",
    "print(detoxify(test_sentence))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-04T16:58:15.408900800Z",
     "start_time": "2023-11-04T16:57:29.388879700Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You want to fool me so i don't know what's going on.\n"
     ]
    }
   ],
   "source": [
    "# Test the function with a new sentence\n",
    "test_sentence = \"Trying to keep me fucking drugged so I don't know what's going on.\"\n",
    "print(detoxify(test_sentence))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-04T16:58:36.826423100Z",
     "start_time": "2023-11-04T16:58:34.407133400Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Oh, man, i wanted an old american football game, man!\n"
     ]
    }
   ],
   "source": [
    "# Test the function with a new sentence\n",
    "test_sentence = \"Damn,man,i wanted the old football coach,man!\"\n",
    "print(detoxify(test_sentence))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-04T16:58:41.753841400Z",
     "start_time": "2023-11-04T16:58:40.199926800Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "data": {
      "text/plain": "Downloading (…)lve/main/config.json:   0%|          | 0.00/629 [00:00<?, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "37e3148142dd48188caa3be30cba16df"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rafai\\PycharmProjects\\Text De-toxification\\venv\\lib\\site-packages\\huggingface_hub\\file_download.py:137: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\rafai\\.cache\\huggingface\\hub. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to see activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "data": {
      "text/plain": "Downloading model.safetensors:   0%|          | 0.00/268M [00:00<?, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "774419f193334792a694da210c48f4fa"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Downloading (…)okenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "34feb692245040d3a5b813f520736799"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Downloading (…)solve/main/vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "02b3a56ed726406380c237cab941866a"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "classifier = pipeline('sentiment-analysis', model='distilbert-base-uncased-finetuned-sst-2-english')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-04T16:59:46.566798800Z",
     "start_time": "2023-11-04T16:58:44.170504500Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "def is_toxic(text_to_analyze, comments = False):\n",
    "  # Run the classifier (model and tokenizer)\n",
    "  results = classifier(text_to_analyze)\n",
    "\n",
    "  # Interpret the results\n",
    "  for result in results:\n",
    "      label = result['label']\n",
    "      score = result['score']\n",
    "\n",
    "      # Heuristic for toxicity based on negative sentiment score\n",
    "      res = label == 'NEGATIVE' and score > TOXICITY_THRESHOLD\n",
    "      if comments:\n",
    "        # Print results\n",
    "        print(f\"Label: {label}, Score: {score}\")\n",
    "        if res:\n",
    "            print(\"The text may be considered toxic.\")\n",
    "        else:\n",
    "            print(\"The text is unlikely to be toxic.\")\n",
    "      return res"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-04T17:00:10.907263900Z",
     "start_time": "2023-11-04T17:00:10.857268900Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i like that shit\n",
      "Label: POSITIVE, Score: 0.6746519207954407\n",
      "The text is unlikely to be toxic.\n",
      "Is toxic: False\n"
     ]
    }
   ],
   "source": [
    "# Example text\n",
    "toxic_text = \"i like that shit\"\n",
    "text_to_analyze =detoxify(toxic_text)\n",
    "print(text_to_analyze)\n",
    "print(\"Is toxic:\", is_toxic( text_to_analyze, True))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-04T17:00:16.707471Z",
     "start_time": "2023-11-04T17:00:12.334115100Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
